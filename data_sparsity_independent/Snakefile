import os
import pandas as pd

# add scripts dir to path
code_dir = "/home/jsadler/drb-dl-model/river_dl"
shell.prefix("module load analytics cuda100/toolkit/10.0.130 \n \
              run_training -e /home/jsadler/.conda/envs/rgcn --no-node-list ")

from river_dl.preproc_utils import prep_data
from river_dl.postproc_utils import predict_from_file, combine_overall, combined_reach_specific, combine_csvs
data_dir = "/home/jsadler/drb-dl-model/data/in"
out_dir = f"/caldera/projects/usgs/water/iidd/datasci/drb_ml_model/experiments/subset/{config['exp_name']}"
x_vars = ['seg_rain', 'seg_tave_air', 'seginc_swrad', 'seg_length', 'seginc_potet', 'seg_slope', 'seg_humid', 'seg_elev']
num_replicates = 10


rule all:
    input:
        f"{out_dir}/exp_combined_metrics.csv",
        f"{out_dir}/exp_combined_reach_metrics.csv"


rule prep_io_data:
    input:
         f"{data_dir}/obs_temp_full",
         f"{data_dir}/obs_flow_full",
         f"{data_dir}/uncal_sntemp_input_output_subset",
         f"{data_dir}/distance_matrix_subset.npz",
         catch_attr = f"{data_dir}/seg_attr_drb.feather"
    output:
        "{outdir}/ex_flow_red_{flow_red}_temp_red_{temp_red}/{run_id}/prepped.npz"
    params:
        test_start_date='2004-09-30',
        n_test_yr=12
    run:
        prep_data(input[0], input[1], input[2], input[3], x_vars,
                  catch_prop_file=input['catch_attr'],
                  reduce_temp_trn=float(wildcards.temp_red),
                  reduce_flow_trn=float(wildcards.flow_red),
                  exclude_file=config.get('exclude_file'),
                  test_start_date=params.test_start_date,
                  log_q=True,
                  n_test_yr=params.n_test_yr, out_file=output[0])


# this must be a shell command so that the correct GPU libraries are loaded and used
rule train:
    input:
         "{outdir}/ex_{experiment}/{run_id}/prepped.npz"
    output:
        directory("{outdir}/ex_{experiment}/{run_id}/trained_weights/"),
        directory("{outdir}/ex_{experiment}/{run_id}/pretrained_weights/")
    params:
        # getting the base path to put the training outputs in
        # I omit the last slash (hence '[:-1]' so the split works properly
        run_dir=lambda wildcards, output: os.path.split(output[0][:-1])[0],
        rmse_tmp_wgt= 0.5,
        flow_in_temp="-q", 
        pt_epochs=200,
        ft_epochs=100,
    shell:
         """
         "python {code_dir}/train_model.py -o {params.run_dir} -i {input[0]} -m {output[0]} -p {params.pt_epochs} -f {params.ft_epochs} {params.flow_in_temp} --pt_temp_wgt {params.rmse_tmp_wgt} --ft_temp_wgt {params.rmse_tmp_wgt}" 
         """

rule make_predictions:
    input: 
        "{outdir}/ex_{experiment}/{run_id}/trained_weights/",
        "{outdir}/ex_{experiment}/{run_id}/prepped.npz",
    params:
        hidden_size=20,
        half_tst=True,
    output:
        "{outdir}/ex_{experiment}/{run_id}/{partition}_preds.feather",
    group: "post_proc"
    run:
        predict_from_file(input[0], input[1], params.hidden_size,
                          wildcards.partition, output[0], flow_in_temp=True,
                          half_tst=params.half_tst, logged_q=True)


rule combined_metrics:
    input:
         "{outdir}/ex_{experiment}/{run_id}/trn_preds.feather",
         "{outdir}/ex_{experiment}/{run_id}/tst_preds.feather",
         f"{data_dir}/obs_temp_full",
         f"{data_dir}/obs_flow_full"
    output:
         "{outdir}/ex_{experiment}/{run_id}/overall_run_metrics.csv"
    group: "post_proc"
    run:
        combine_overall(input[0], input[1], input[2], input[3], output[0])


def combine_replicate_csvs(csvs, flow_red, temp_red, seg_id_idx=False):
    df_list = []
    for i, metric_file in enumerate(csvs):
        df = pd.read_csv(metric_file)
        df['run_id'] = i
        df_list.append(df)
    df = pd.concat(df_list, axis=0)
    df['flow_red'] = float(flow_red)
    df['temp_red'] = float(temp_red)
    return df

rule combined_run_metrics:
    input:
         expand("{outdir}/ex_flow_red_{flow_red}_temp_red_{temp_red}/{run_id}/overall_run_metrics.csv",
                run_id=list(range(num_replicates)), allow_missing=True)
    output:
         "{outdir}/ex_flow_red_{flow_red}_temp_red_{temp_red}/overall_metrics.csv"
    group: "post_proc"
    run:
        df = combine_replicate_csvs(input, wildcards.flow_red, wildcards.temp_red)
        df.to_csv(output[0], index=False)


rule calc_reach_specific_metrics:
    input: 
         "{outdir}/ex_{experiment}/{run_id}/trn_preds.feather",
         "{outdir}/ex_{experiment}/{run_id}/tst_preds.feather",
         f"{data_dir}/obs_temp_full",
         f"{data_dir}/obs_flow_full",
    output:
        "{outdir}/ex_{experiment}/{run_id}/reach_metrics.csv",
    group: "post_proc"
    run:
        combined_reach_specific(input[0], input[1], input[2], input[3], output[0])


rule combined_run_reach_metrics:
    input:
         expand("{outdir}/ex_flow_red_{flow_red}_temp_red_{temp_red}/{run_id}/reach_metrics.csv",
                run_id=list(range(num_replicates)), allow_missing=True)
    output:
         "{outdir}/ex_flow_red_{flow_red}_temp_red_{temp_red}/overall_reach_metrics.csv"
    group: "post_proc"
    run:
        df = combine_replicate_csvs(input, wildcards.flow_red, wildcards.temp_red, seg_id_idx=True)
        df.to_csv(output[0], index=False)


def combine_exper_metrics(experiment_metric_files):
    df_list = []
    for exp in experiment_metric_files:
        df_list.append(pd.read_csv(exp))
    df_comb = pd.concat(df_list)
    return df_comb

rule combine_exp_metrics:
    input:
        expand("{outdir}/ex_flow_red_{flow_red}_temp_red_{temp_red}/overall_metrics.csv",
                flow_red=config['flow_reductions'], temp_red=config['temp_reductions'],
                allow_missing=True)
    output:
        "{outdir}/exp_combined_metrics.csv"
    run:
        combined = combine_exper_metrics(input)
        combined.to_csv(output[0], index=False)

rule combine_exp_reach_metrics:
    input:
        expand("{outdir}/ex_flow_red_{flow_red}_temp_red_{temp_red}/overall_reach_metrics.csv",
                flow_red=config['flow_reductions'], temp_red=config['temp_reductions'],
                allow_missing=True)
    output:
        "{outdir}/exp_combined_reach_metrics.csv"
    run:
        combined = combine_exper_metrics(input)
        combined.to_csv(output[0], index=False)

